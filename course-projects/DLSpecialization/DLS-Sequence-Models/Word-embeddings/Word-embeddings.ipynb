{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158a2b17",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "In this notebook, we use pretrained word embeddings by GloVe to measure similarity between different words, and to solve word analogy problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d391ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6fffb2",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Read Pretrained Word Vectors </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2724c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        word_to_vec_map = {}\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "            \n",
    "    return word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a35eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a9f39aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion:\n",
      "[ 0.60093    0.012934  -0.61032   -0.13871    1.2507     0.10128\n",
      " -0.20073   -1.1283     0.60857   -0.16666    0.22419    0.61781\n",
      "  0.50102   -0.22303   -0.011922   0.24229    0.82199    0.5748\n",
      " -1.9703     0.044589   0.22157   -0.26673   -0.005156  -0.36311\n",
      " -0.42483   -0.79237   -1.557      0.22124   -0.32143   -0.46747\n",
      "  1.0604     0.84237    0.045337   0.86075   -0.085506   0.0058815\n",
      " -0.16237   -1.0329    -0.25763   -0.65854   -0.13647    0.3653\n",
      " -0.61384   -0.54004    0.24051   -0.23007   -0.31155   -1.3485\n",
      "  0.4327    -0.34512  ]\n",
      "chair:\n",
      "[-1.0443e+00  4.9202e-01 -7.5978e-01 -3.9224e-01  8.1217e-01 -3.9287e-02\n",
      "  1.6706e-02 -6.8629e-01 -7.8359e-02 -1.3214e+00 -1.5354e-01  2.0438e-01\n",
      " -4.6503e-01  1.2145e+00 -1.8217e-01  2.7451e-01 -2.4086e-01  7.1145e-01\n",
      "  3.2470e-01 -7.1320e-01  6.6721e-01  7.1307e-01 -1.0394e-01 -3.8439e-01\n",
      " -2.0260e-01 -1.4419e+00  4.2644e-01  5.9436e-01 -1.3615e+00  1.3784e-03\n",
      "  1.8734e+00 -1.1334e-01 -8.8115e-01 -2.1715e-01 -5.6606e-01  1.4152e-01\n",
      "  2.7673e-01  9.9962e-01  1.0567e+00 -2.9428e-01 -3.1390e-01  1.2729e-01\n",
      " -5.4363e-01  3.9652e-01 -3.2527e-01  3.0536e-01  1.5128e-01 -1.0889e+00\n",
      " -2.0867e-01 -5.2605e-02]\n",
      "of:\n",
      "[ 0.70853    0.57088   -0.4716     0.18048    0.54449    0.72603\n",
      "  0.18157   -0.52393    0.10381   -0.17566    0.078852  -0.36216\n",
      " -0.11829   -0.83336    0.11917   -0.16605    0.061555  -0.012719\n",
      " -0.56623    0.013616   0.22851   -0.14396   -0.067549  -0.38157\n",
      " -0.23698   -1.7037    -0.86692   -0.26704   -0.2589     0.1767\n",
      "  3.8676    -0.1613    -0.13273   -0.68881    0.18444    0.0052464\n",
      " -0.33874   -0.078956   0.24185    0.36576   -0.34727    0.28483\n",
      "  0.075693  -0.062178  -0.38988    0.22902   -0.21617   -0.22562\n",
      " -0.093918  -0.80375  ]\n"
     ]
    }
   ],
   "source": [
    "sample_words = ['lion','chair','of']\n",
    "for word in sample_words:\n",
    "    print(f\"{word}:\\n{word_to_vec_map[word]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99477c6",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Cosine Similarity </span>\n",
    "Cosine similaity, shown by $\\alpha$ here, between two vectors $\\mathbf{u}$ and $\\mathbf{v}$ is simply the cosine of the angle between them:\n",
    "$$\\alpha=\\frac{\\mathbf{u}^{\\mathrm{T}}\\mathbf{v}}{\\lVert \\mathbf{u}\\rVert_2\\lVert \\mathbf{v}\\rVert_2}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c66b6ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    if np.all(u == v):\n",
    "        return 1\n",
    "    \n",
    "    dot = np.dot(u,v) \n",
    "    norm_u = np.sqrt(np.dot(u,u))\n",
    "    norm_v = np.sqrt(np.dot(v,v\n",
    "    \n",
    "    if norm_u*norm_v == 0:\n",
    "        return 0\n",
    "    \n",
    "    cosine_similarity = dot/(norm_u*norm_v)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81de357b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some cosine similarity values:\n",
      "human versus vegtable: 0.14382288655846073\n",
      "girl versus woman: 0.9065280671323898\n",
      "chicken versus television: 0.21441582211490806\n"
     ]
    }
   ],
   "source": [
    "print(\"Some cosine similarity values:\")\n",
    "print(f\"human versus vegtable: {cosine_similarity(word_to_vec_map['human'],word_to_vec_map['vegetable'])}\")\n",
    "print(f\"girl versus woman: {cosine_similarity(word_to_vec_map['girl'],word_to_vec_map['woman'])}\")\n",
    "print(f\"chicken versus television: {cosine_similarity(word_to_vec_map['chicken'],word_to_vec_map['television'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b13284",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Word Analogy Task </span>\n",
    "The objective is to complete this sentence: <font color=\"olive\"> \"*a* is to *b* as *c* is to ____ </font>\"\n",
    "\n",
    "In other words, if $\\mathbf{e}_a$, $\\mathbf{e}_b$, and $\\mathbf{e}_c$ denote the embeddings of, respectively, words *a*, *b*, and *c*, find the word *w* with embedding $\\mathbf{e}_w$ such that $\\mathbf{e}_b-\\mathbf{e}_a\\sim \\mathbf{e}_w-\\mathbf{e}_c$. Here $\\sim$ means similar and we find the word *w* that provides the highest similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d018b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_analogy(word_a, word_b, word_c, word_to_vec_map):\n",
    "    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
    "    e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]\n",
    "    \n",
    "    words = word_to_vec_map.keys()\n",
    "    \n",
    "    max_cosine_sim = -2\n",
    "    best_word = None   \n",
    "    for w in words:\n",
    "        if w == word_c:\n",
    "            continue\n",
    "            \n",
    "        cosine_sim = cosine_similarity(e_b-e_a,word_to_vec_map[w]-e_c)\n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = w\n",
    "        \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61a68084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian :: spain -> spanish\n",
      "man -> woman :: boy -> girl\n"
     ]
    }
   ],
   "source": [
    "triads_to_try = [('italy', 'italian', 'spain'), ('man', 'woman', 'boy')]\n",
    "for triad in triads_to_try:\n",
    "    print(f\"{triad[0]} -> {triad[1]} :: {triad[2]} -> {complete_analogy(*triad, word_to_vec_map)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
