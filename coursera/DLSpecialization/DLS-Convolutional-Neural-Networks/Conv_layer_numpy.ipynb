{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c399c6",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> Convolutional layers by numpy </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30007b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9884d9f",
   "metadata": {},
   "source": [
    "# Zero padding\n",
    "\n",
    "Write a function that pads an input $X$ with shape $(m,n_H,n_W,n_C)$ with zeros along the height and width axes (i.e., axes $1$ and $2$). Here, $m$, $n_H$, $n_W$, and $n_C$ denote number of training examples, height and width of the image, and number channels, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c129880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, p):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    X: data; X.shape = (m, n_H, n_W, n_C)\n",
    "    p: padding; int\n",
    "    \n",
    "    Output:\n",
    "    X_p: padded image; X_p.shape (m, n_H+2p, n_W+2p, n_C)\n",
    "    \"\"\"\n",
    "    X_p = np.pad(X,((0,0),(p,p),(p,p),(0,0)),mode='constant',constant_values=0)\n",
    "    \n",
    "    return X_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66e44452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.25354314 -0.11923911 -0.13090589]\n",
      " [ 0.68255556 -1.30304607 -1.33926508]\n",
      " [-2.53665143 -0.07492347  0.12569815]]\n",
      "X.shape = (1, 3, 3, 2)\n",
      "[[ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          1.25354314 -0.11923911 -0.13090589  0.        ]\n",
      " [ 0.          0.68255556 -1.30304607 -1.33926508  0.        ]\n",
      " [ 0.         -2.53665143 -0.07492347  0.12569815  0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "X_p.shape = (1, 5, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randn(1, 3, 3, 2)\n",
    "print(X[0,:,:,0])\n",
    "print(f\"X.shape = {X.shape}\")\n",
    "X_p = zero_pad(X, 1)\n",
    "print(X_p[0,:,:,0])\n",
    "print(f\"X_p.shape = {X_p.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75809a3",
   "metadata": {},
   "source": [
    "# Single convolution\n",
    "write a function that convolves a slice of the last layer activation with shape $(f,f,n_C^{\\ell-1})$ by a filter/kernel $W$ with shape $(f,f,n_C^{\\ell-1})$ and bias $b$ with shape $(1,1,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "990cea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    a_slice_prev: activation from previous layer. a_slice_prev.shape = (f, f, n_C_prev)\n",
    "    W: filter weights; W.shape = (f, f, n_C_prev)\n",
    "    b: bias parameter; b.shape = (1, 1, 1)\n",
    "    \n",
    "    Output:\n",
    "    z: corresponding linear activation of the current layer; int\n",
    "    \"\"\"\n",
    "    z = np.multiply(W,a_slice_prev).sum()+b.item()\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9aaffecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first channel of a:\n",
      "[[8 4 1]\n",
      " [9 4 7]\n",
      " [8 4 4]]\n",
      "second channel of a:\n",
      "[[1 6 6]\n",
      " [3 3 3]\n",
      " [3 4 6]]\n",
      "first channel of kernel:\n",
      "[[1 1 0]\n",
      " [0 1 1]\n",
      " [0 1 0]]\n",
      "second channel of kernel:\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]]\n",
      "z = 37.0\n"
     ]
    }
   ],
   "source": [
    "a_slice_prev = np.random.randint(10,size=(3,3,2))\n",
    "print(f\"first channel of a:\\n{a_slice_prev[:,:,0]}\")\n",
    "print(f\"second channel of a:\\n{a_slice_prev[:,:,1]}\")\n",
    "W = np.random.randint(2,size=(3,3,2))\n",
    "print(f\"first channel of kernel:\\n{W[:,:,0]}\")\n",
    "print(f\"second channel of kernel:\\n{W[:,:,1]}\")\n",
    "z = conv_single(a_slice_prev, W, np.zeros((1,1,1)))\n",
    "print(f\"z = {z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a583135",
   "metadata": {},
   "source": [
    "# Convolution layer\n",
    "Now write a full conv layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76cbb292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(A_prev, W, b, hyper_parameters):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    A_prev: activations of the previous layer; A_prev.shape = (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W: filter weights; W.shape = (f, f, n_C_prev, n_C)\n",
    "    b: bias parameters; b.shape (1, 1, 1, n_C)\n",
    "    hyper_parameters: pad and stride; parameters.shape = (2,)\n",
    "        \n",
    "    Output:\n",
    "    z: corresponding linear activation of the current layer; z.shape = (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    p = hyper_parameters[\"pad\"]\n",
    "    s = hyper_parameters[\"stride\"]\n",
    "    \n",
    "    n_H, n_W = int((n_H_prev+2*p-f)/s+1), int((n_W_prev+2*p-f)/s+1)\n",
    "    z = np.zeros((m, n_H, n_W, n_C))\n",
    "    A_prev_pad = zero_pad(A_prev, p)\n",
    "    for i in range(m):\n",
    "        for c in range(n_C):\n",
    "            for h in range(n_H):\n",
    "                for w in range(n_W):\n",
    "                    h_lo, w_lo = h*s, w*s # start (low) cell in A_prev_pad\n",
    "                    h_hi, w_hi = h_lo+f, w_lo+f # end (hi) cell in A_prev_pad\n",
    "                    a_slice_prev = A_prev_pad[i,h_lo:h_hi,w_lo:w_hi,:]\n",
    "                    z[i,h,w,c] = conv_single(a_slice_prev, W[:,:,:,c], b[0,0,0,c])\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cf9ad",
   "metadata": {},
   "source": [
    "# Pool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07978239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool(A_prev, hyper_parameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    A_prev: activations of the previous layer; A_prev.shape = (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hyper_parameters: f and stride; parameters.shape = (2,)\n",
    "    mode: pooling mode (\"max\" or \"average\")\n",
    "    \n",
    "    Output:\n",
    "    A: output of the pool layer; A.shape = (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    f = hyper_parameters[\"f\"]\n",
    "    s = hyper_parameters[\"stride\"]\n",
    "    \n",
    "    n_H = int((n_H_prev-f)/s+1)\n",
    "    n_W = int((n_W_prev-f)/s+1)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    for i in range(m):\n",
    "        for c in range(n_C):\n",
    "            for h in range(n_H):\n",
    "                for w in range(n_W):\n",
    "                    h_lo, w_lo = h*s, w*s\n",
    "                    h_hi, w_hi = h_lo+f, w_lo+f\n",
    "                    a_slice_prev = A_prev[i,h_lo:h_hi,w_lo:w_hi,c]\n",
    "                    if mode == \"max\":\n",
    "                        A[i,h,w,c] = np.max(a_slice_prev)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i,h,w,c] = np.mean(a_slice_prev)\n",
    "    \n",
    "    return A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
